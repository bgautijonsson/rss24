{
  "hash": "091ff389b83c5391830672f43aa35968",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Gaussian Copulas for Large Spatial Fields\"\nsubtitle: \"Modeling Data-Level Spatial Dependence in Multivariate Generalized Extreme Value Distributions\"\nauthor: \"Brynjólfur Gauti Guðrúnar Jónsson\"\ninstitute: \"University of Iceland\"\nformat: \n  beamer: \n    aspectratio: 169\n---\n\n::: {.cell}\n\n:::\n\n\n\n## Introduction\n::: {.columns}\n\n::: {.column width=\"70%\"}\n- UKCP Local Projections on a 5km grid over the UK (1980-2080)\n- Challenge: Modeling maximum daily precipitation in yearly blocks\n  - 43,920 spatial locations on a 180 x 244 grid\n- Two aspects of spatial dependence:\n  1. GEV parameters (ICAR models)\n  2. Data-level dependence (Copulas)\n:::\n\n::: {.column width=\"30%\"}\n![](images/ukcp_data.png){width=\"100%\"}\n:::\n\n:::\n\n## Calculating Multivariate Normal Densities\n\n::: {.columns}\n\n::: {.column width=\"50%\"}\n### Log Density Formula\n\n$$\n\\log f(\\mathbf{x}) \\propto \\frac{1}{2}\\left(\\log |\\mathbf{Q}| - \\mathbf{x}^T\\mathbf{Q}\\mathbf{x}\\right)\n$$\n\n### Key Components\n\n1. **Log Determinant**: $\\log |\\mathbf{Q}|$\n   - Constant for a given precision matrix\n2. **Quadratic Form**: $\\mathbf{x}^T\\mathbf{Q}\\mathbf{x}$\n   - Needs calculation for each density evaluation\n:::\n\n::: {.column width=\"50%\"}\n### Computational Challenges\n\n- Log determinant calculation\n  - Time complexity: $O(n^3)$ for naive methods\n  - Memory complexity: $O(n^2)$\n- Quadratic form calculation\n  - Time complexity: $O(n^2)$\n  - Critical for performance in large spatial fields\n\n### Spatial Model Considerations\n\n- Some models (e.g., ICAR) avoid log determinant calculation\n- Efficient computation crucial for large-scale applications\n:::\n\n:::\n\n## Spatial Models\n\n### Conditional Autoregression (CAR)\n::: {.columns}\n::: {.column width=\"50%\"}\n\n* $\\mathbf{D}$ is a diagonal matrix with $D_{ii} = n_i$, the number of neighbours of $i$\n* $\\mathbf{A}$ is the adjacency matrix with $A_{ij} = A_{ji} = 1$ if $i \\sim j$\n* $\\tau$ models overall precision\n\n:::\n::: {.column width=\"50%\"}\n$$\n\\begin{aligned}\n\\mathbf{x} &\\sim N(\\mathbf{0}, \\tau \\mathbf{Q}) \\\\\n\\mathbf{Q} &= \\mathbf{D}\\left(\\mathbf{I} - \\alpha \\mathbf{A} \\right)\n\\end{aligned}\n$$\n:::\n::: \n\n\n### Besag's Intrinsic Conditional Autoregression (ICAR)\n::: {.columns}\n::: {.column width=\"50%\"}\n\n* $\\alpha = 1$, so $\\mathbf Q$ is singular, but constant\n* Don't have to calculate $\\log |\\mathbf{Q}|$\n* $\\tau$ is a precision parameter\n:::\n::: {.column width=\"50%\"}\n$$\n\\begin{aligned}\n\\mathbf{x} &\\sim N(\\mathbf{0}, \\tau \\mathbf{Q}) \\\\\n\\mathbf{Q} &= \\mathbf{D} - \\mathbf{W}\n\\end{aligned}\n$$\n:::\n:::\n\n## Spatial Models\n\n### BYM (Besag-York-Mollié) Model\n::: {.columns}\n::: {.column width=\"50%\"}\n\n* $\\mathbf{u}$ is the structured spatial component (Besag model)\n* $\\mathbf{v}$ is the unstructured component (i.i.d. normal)\n* $\\tau_u$ and $\\tau_v$ are precision parameters for each component\n:::\n::: {.column width=\"50%\"}\n$$\n\\begin{aligned}\n\\mathbf{x} &= \\mathbf{u} + \\mathbf{v} \\\\\n\\mathbf{u} &\\sim \\mathrm{ICAR}(\\tau_u) \\\\\n\\mathbf{v} &\\sim N(\\mathbf{0}, \\tau_v^{-1})\n\\end{aligned}\n$$\n:::\n:::\n\n### BYM2  Model\n::: {.columns}\n::: {.column width=\"50%\"}\n\n* Rewrite the combination to get proper scaling\n* $\\rho$ models how much of variance is spatial\n* $s$ is a scaling factor chosen to make $\\mathrm{Var}(\\mathbf u_i) \\approx 1$\n:::\n::: {.column width=\"50%\"}\n$$\n\\begin{aligned}\n\\mathbf{x} &= \\left(\\left(\\sqrt{\\rho/s}\\right)\\mathbf{u} + \\left(\\sqrt{1 - \\rho}\\right) \\mathbf{v} \\right)\\sigma \\\\\n\\mathbf{u} &\\sim \\mathrm{ICAR}(1) \\\\\n\\mathbf{v} &\\sim N(\\mathbf{0}, n)\n\\end{aligned}\n$$\n:::\n:::\n\n## Spatial Modeling on Parameter-level\n\n::: {.columns}\n\n::: {.column width=\"50%\"}\n\n-  $\\mu = \\mu_0 \\left(1 + \\Delta \\left(t - t_0\\right)\\right)$, location\n- $\\sigma$: scale\n- $\\xi$: shape\n$$\n\\small{\n\\begin{aligned}\n\\log(\\mu_0) = \\psi &\\sim \\mathrm{BYM2}(\\mu_\\psi, \\rho_\\psi, \\sigma_\\psi) \\\\\n\\log(\\mu_0) - \\log(\\sigma) = \\tau &\\sim \\mathrm{BYM2}(\\mu_\\tau, \\rho_\\tau, \\sigma_\\tau) \\\\\nf_\\xi(\\xi) = \\phi &\\sim \\mathrm{BYM2}(\\mu_\\phi, \\rho_\\phi, \\sigma_\\phi) \\\\\nf_\\Delta(\\Delta) = \\gamma &\\sim \\mathrm{BYM2}(\\mu_\\gamma, \\rho_\\gamma, \\sigma_\\gamma)\n\\end{aligned}\n}\n$$\n\n![](images/bym_table.png)\n\n:::\n\n::: {.column width=\"50%\"}\n![](images/facet_constrained.png)\n:::\n\n:::\n\n## From Parameter-level to Data-level Dependence\n\n::: {.columns}\n\n::: {.column width=\"50%\"}\n### Parameter-level Dependence\n- Assumes conditional independence\n- Biased joint probability estimates\n- Underestimates parameter variance\n:::\n\n::: {.column width=\"50%\"}\n### Copula\n- Improves joint probabilities\n- Enhances spatial risk assessment\n- Better variance estimates\n:::\n\n:::\n\n::: {style=\"font-size:65%; margin-top:20px;\"}\n**Sklar's Theorem**: For any multivariate distribution $H$, there exists a unique copula $C$ such that:\n\n$$\nH(\\mathbf x) = C(F_1(x_1), \\dots, F_d(x_d))\n$$\n\nwhere $F_i$ are marginal distributions. We can also write this as a log-density\n\n$$\n\\log h(x) = \\log c(F_1(x_1), \\dots, F_d(x_d)) \\sum_{i=1}^d \\log f_i(x_i)\n$$\n\n:::\n\n## Our Approach: Matérn-like Gaussian Copula\n\n### Marginal CDFs, $F_i(x_i)$, is $\\mathrm{GEV}(\\mu_i, \\sigma_i, \\xi_i)$\n$$\n\\begin{aligned}\n\\log h(\\mathbf x) &= \\log c(u_1, \\dots, u_d) + \\sum_{i=1}^d f_{\\mathrm{GEV}}(x_i \\vert \\mu_i, \\sigma_i, \\xi_i) \\\\\nu_i &= F_{\\mathrm{GEV}}(x_i \\vert \\mu_i, \\sigma_i, \\xi_i)\n\\end{aligned}\n$$\n\n### Gaussian Copula\n\n$$\n\\begin{aligned}\n\\log c(\\mathbf u) &\\propto \\frac{1}{2}\\left(\\log |\\mathbf{Q}| - \\mathbf{z}^T\\mathbf{Q}\\mathbf{z} + \\mathbf{z}^T\\mathbf{z}\\right) \\\\\n\\mathbf{z} &= \\Phi^{-1}(\\mathbf u)\n\\end{aligned}\n$$\n\n\n## The Precision Matrix\n\n$\\mathbf Q$ defined as Kronecker sum of two AR(1) precision matrices\n\n$$\n\\mathbf{Q} = \\left( \\mathbf{Q}_{\\rho_1} \\otimes \\mathbf{I_{n_2}} + \\mathbf{I_{n_1}} \\otimes \\mathbf{Q}_{\\rho_2} \\right)^{\\nu + 1}, \\quad \\nu \\in \\{0, 1, 2\\}\n$$\n\n$$\n\\mathbf{Q}_{\\rho} = \\frac{1}{1-\\rho^2}\n\\begin{bmatrix}\n1 & -\\rho & 0 & \\cdots & 0 \\\\\n-\\rho & 1+\\rho^2 & -\\rho & \\cdots & 0 \\\\\n0 & -\\rho & 1+\\rho^2 & \\cdots & 0 \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n0 & 0 & 0 & \\cdots & 1\n\\end{bmatrix}\n$$\n\n\n## Eigendecomposition\n\n\nBecause of how $\\mathbf{Q}$ is defined, we know that\n\n$$\n\\begin{aligned}\n\\mathbf{Q} &= \\mathbf{V}\\boldsymbol{\\Lambda}\\mathbf{V} \\\\\n&= (\\mathbf{V_{\\rho_1}} \\otimes \\mathbf{V_{\\rho_2}})(\\boldsymbol \\Lambda_{\\rho_1} \\otimes \\mathbf{I} + \\mathbf{I} \\otimes \\boldsymbol \\Lambda_{\\rho_2})^{\\nu + 1}(\\mathbf{V_{\\rho_1}} \\otimes \\mathbf{V_{\\rho_2}})^T \\\\\n\\mathbf{Q}_{\\rho_1} &= \\mathbf{V_{\\rho_1}}\\boldsymbol \\Lambda_{\\rho_1}\\mathbf{V_{\\rho_1}}^T \\qquad \\& \\qquad\n\\mathbf{Q}_{\\rho_2} = \\mathbf{V_{\\rho_2}}\\boldsymbol \\Lambda_{\\rho_2}\\mathbf{V_{\\rho_2}}^T\n\\end{aligned}\n$$\n\nSpectral decomposition defined by value/vector pairs of smaller matrices\n\n:::: {.columns}\n::: {.column width=\"50%\"}\n$$\n\\left\\{\\lambda_{\\rho_1}\\right\\}_i + \\left\\{\\lambda_{\\rho_2}\\right\\}_j\n$$\n:::\n\n::: {.column widht=\"50%\"}\n$$\n\\left\\{\\mathbf{v}_{\\rho_1}\\right\\}_i \\otimes \\left\\{\\mathbf{v}_{\\rho_2}\\right\\}_j\n$$\n:::\n::::\n\n* Problem: $\\boldsymbol \\Sigma_{ii} = \\left(\\mathbf Q^{-1} \\right)_{ii} \\neq  1$\n* Solution: $\\mathbf{\\widetilde  Q} = \\mathbf{D}\\mathbf{Q}\\mathbf{D}$, where $\\mathbf D_{ii} = \\sqrt{\\boldsymbol \\Sigma_{ii}}$\n\n## Marginal Standard Deviations\n\n$$\n\\boldsymbol \\Sigma = \\mathbf Q^{-1} = (\\mathbf{V}\\boldsymbol\\Lambda\\mathbf{V}^T)^{-1} = \\mathbf{V}\\boldsymbol \\Lambda^{-1}\\mathbf{V}\n$$\n\nWe know that if $A = BC$ then $A_{ii} = B_{i, .} C_{., i}$, so\n\n$$\n\\boldsymbol \\Sigma_{ii} = \\sum_{k=1}^{n} v_{ik} \\frac{1}{\\lambda_k} (v^T)_{ki} = \\sum_{k=1}^{n} v_{ik} \\frac{1}{\\lambda_k} v_{ik} = \\sum_{k=1}^{n} v_{ik}^2 \\frac{1}{\\lambda_k}\n$$\n\nCompute vector $\\sigma^2$ containing all marginal variances\n\n$$ \n\\sigma^2 = \\sum_{i = 1}^{n_1} \\sum_{j=1}^{n_2} \\frac{\\left(\\left\\{\\mathbf{v}_{\\rho_1}\\right\\}_i \\otimes \\left\\{\\mathbf{v}_{\\rho_2}\\right\\}_j\\right)^{2}}{\\quad\\left(\\left\\{\\lambda_{\\rho_1}\\right\\}_i + \\left\\{\\lambda_{\\rho_2}\\right\\}_j\\right)^{\\nu+1}}\n$$\n\n## Marginal Standard Deviations\n\n:::: {.columns}\n::: {.column width=\"58%\"}\n\\AddToHookNext{env/Highlighting/begin}{\\tiny}\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim1 <- 50; dim2 <- 50\nrho1 <- 0.5; rho2 <- 0.3\nnu <- 2\nQ1 <- make_AR_prec_matrix(dim1, rho1)\nQ2 <- make_AR_prec_matrix(dim2, rho2)\nI1 <- Matrix::Diagonal(dim1)\nI2 <- Matrix::Diagonal(dim2)\nQ <- temp <- kronecker(Q1, I2) + kronecker(I1, Q2)\nfor (i in seq_len(nu)) Q <- Q %*% temp\n```\n:::\n\n\n:::\n\n::: {.column width=\"42%\"}\n\\AddToHookNext{env/Highlighting/begin}{\\tiny}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmsd <- function(Q1, Q2) {\n  E1 <- eigen(Q1)\n  E2 <- eigen(Q2)\n  marginal_sd_eigen(\n    E1$values, E1$vectors, dim1,\n    E2$values, E2$vectors, dim2,\n    nu\n  ) |> sort()\n}\n```\n:::\n\n\n:::\n:::: \n\n\\AddToHookNext{env/Highlighting/begin}{\\tiny}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nbench::mark(\n  \"solve\" = solve(Q) |> diag() |> sqrt() |> sort(),\n  \"inla.qinv\" = inla.qinv(Q) |> diag() |> sqrt() |> sort(),\n  \"marginal_sd_eigen\" = msd(Q1, Q2),\n  iterations = 10, filter_gc = FALSE\n)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 3 x 6\n  expression             min   median `itr/sec` mem_alloc `gc/sec`\n  <bch:expr>        <bch:tm> <bch:tm>     <dbl> <bch:byt>    <dbl>\n1 solve                1.27s    1.29s     0.757   78.17MB    0.757\n2 inla.qinv          358.2ms 367.86ms     2.72     4.33MB    0    \n3 marginal_sd_eigen   3.29ms   3.35ms   279.     649.35KB    0    \n```\n\n\n:::\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": null,
    "postProcess": false
  }
}